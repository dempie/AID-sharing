---
title: "R Notebook"
output: html_notebook
---
In this notebook I will add the fucntion useful for this project that I have created or stolen from someone.

## prepare_munge

This function is useful to format GWAS summary statistic as the munge function from GenomicSEM wants them. 

```{r prepare_munge }
prepare_munge <- function(sum_stats, rsID, the_effect_allele, the_non_effect_allele, pvalue, effect_size, the_SE=NA, the_chr=NA, the_bp=NA, to_remove=NA, path = NA){
  #an error if arguments are not provided 
  if (missing(sum_stats) | missing(rsID) | missing(the_effect_allele) | missing(the_non_effect_allele) |missing(pvalue) | missing(effect_size) ) {
    stop( 'At least one argument is missing')
    
      } else {
        
          require(dplyr)
          require(data.table)
          sum_stats <- sum_stats  %>% rename(c(SNP = rsID, A1 = all_of(the_effect_allele), A2 = all_of(the_non_effect_allele), p = all_of(pvalue), effect = all_of(effect_size)))
          sum_stats$SNP <- tolower(sum_stats$SNP)
          sum_stats$p <- as.numeric(sum_stats$p)
          sum_stats$effect <- as.numeric(sum_stats$effect)
          
          #conditional options 
                #remove columns
                if(!is.na(to_remove[1])){sum_stats <- select(sum_stats,-(all_of(to_remove)))} 
                      
                #rename SE column
                if(!is.na(the_SE)){ 
                      sum_stats <- rename(sum_stats, SE=all_of(the_SE))
                      sum_stats$SE <- as.numeric(sum_stats$SE)
                      }
              
                #rename the CHR column
                if(!is.na(the_chr)){ sum_stats <-  rename(sum_stats, CHR=all_of(the_chr))}
              
                #rename the BP column
                if(!is.na(the_bp)){ sum_stats <- rename(sum_stats, BP=all_of(the_bp))}
          
                #save the file if a path is provided
                if(is.na(path)){
                    invisible(sum_stats)
                  
                  
                } else {
                  
                  fwrite(sum_stats, path, sep = '\t', col.names = T, row.names = F, quote = F)
                  invisible(sum_stats)
                }
              }
}

```


## qc_summary_stats 
takes as output of prepare_munge and outputs the number of SNP with rsID, 
```{r qc summary stats}
qc_summary_stats <- function(sum_stats, plots=F){
          #compute number of SNPs
          n_SNPs <- nrow(sum_stats)
          
          #compute the number of unique rsIDs 
          sum_stats_rsIDs<- sum_stats[grep('rs',sum_stats$SNP),]
          n_rsIDs <- length(unique(sum_stats_rsIDs$SNP))
          
          SNP_per_chr <- vector(mode='integer', length = 22)
          rsID_per_chr <-  vector(mode='integer', length = 22)
          
          #compute the number of unique rsIDs and SNPs per chromosome 
          for(i in c(1:22)){
            
                SNP_per_chr[i] <- nrow(sum_stats[sum_stats$CHR== i ,]) 
                rsID_per_chr[i] <- length(unique(sum_stats_rsIDs[sum_stats_rsIDs$CHR == i, ]$SNP))
          }
          
          qc_metrics_SNPs <- cbind(Chromosome = c(1:22) ,n_SNPs = SNP_per_chr )
          qc_metrics_rsIDs <- cbind(Chromosome = c(1:22) ,n_rsIDs = rsID_per_chr )
          
          cat(paste0( 'Total number of SNP  ' , n_SNPs , '\n', 
                      'Total number of SNP with rsID  ', n_rsIDs, '\n')
          )
          
          output <- list(qc_SNPs = qc_metrics_SNPs, qc_rsIDs=qc_metrics_rsIDs )
          
          
          
          if(plots==T){

            barplot(t(output$qc_SNPs) , main = 'Number of unique rsID per chromosome',  ylab = 'Number of SNP', 
                    names.arg = k$qc_SNPs[,1], cex.names = 0.8, 
                    legend.text =  paste0( 'Total number of SNP with rsID  ', n_rsIDs))
          }
          
          return(output)   
          
}
```


## semPlotModel_GSEM

This function transforms the output from genomic sem in an object that can be used by the semPlot function to draw paths for factor analysis representation. 
```{r semPlotModel_GSEM}
semPlotModel_GSEM=function(gsem.object=GWISoutput , est.label="STD_All"){ 
  require(semPlot)
  object=gsem.object$results
  object$free=0
  numb=1:length(which(object$op!="~~"))
  object$free[which(object$op!="~~")]=numb
  varNames <- lavaanNames(object, type = "ov")
  factNames <- lavaanNames(object, type = "lv")
  factNames <- factNames[!factNames %in% varNames]
  n <- length(varNames)
  k <- length(factNames)
  if (is.null(object$label)) 
    object$label <- rep("", nrow(object))
  semModel <- new("semPlotModel")
  object$est <- object[,est.label]
  if (is.null(object$group)) 
    object$group <- ""
  semModel@Pars <- data.frame(label = object$label, lhs = ifelse(object$op == 
                                                                   "~" | object$op == "~1", object$rhs, object$lhs), edge = "--", 
                              rhs = ifelse(object$op == "~" | object$op == "~1", object$lhs, 
                                           object$rhs), est = object$est, std = NA, group = object$group, 
                              fixed = object$free==0, par = object$free, stringsAsFactors = FALSE)
  semModel@Pars$edge[object$op == "~~"] <- "<->"
  semModel@Pars$edge[object$op == "~*~"] <- "<->"
  semModel@Pars$edge[object$op == "~"] <- "~>"
  semModel@Pars$edge[object$op == "=~"] <- "->"
  semModel@Pars$edge[object$op == "~1"] <- "int"
  semModel@Pars$edge[grepl("\\|", object$op)] <- "|"
  semModel@Thresholds <- semModel@Pars[grepl("\\|", semModel@Pars$edge), 
                                       -(3:4)]
  semModel@Pars <- semModel@Pars[!object$op %in% c(":=", "<", 
                                                   ">", "==", "|", "<", ">"), ]
  semModel@Vars <- data.frame(name = c(varNames, factNames), 
                              manifest = c(varNames, factNames) %in% varNames, exogenous = NA, 
                              stringsAsFactors = FALSE)
  semModel@ObsCovs <- list()
  semModel@ImpCovs <- list()
  semModel@Computed <- FALSE
  semModel@Original <- list(object)
  return(semModel)
  
}
```


## split_sum_stats
This function is meant to seaprate GWAS summary statas in n chunks of x size, and then recover a specific chunk. This is usefull for running job arrays in the cluster. 

```{r split_sum_stats}
split_sum_stats <- function(summary_stats, chunk_size, which_chunk) {
  require(data.table)
  #give a number to the elements of the sum_states
  my_index <- seq_along(1: nrow(summary_stats))
  n <- nrow(summary_stats) 
  chunks <- rep(1:ceiling(n/chunk_size),each=chunk_size)[1:n] #the last piece [1:n] is necessary because otherwise the last chunk will become long as the chunk size and will replicate it thus exciding the length of the sumstats
  a <- split(my_index, chunks)
  summary_stats[ (a[[which_chunk]]) , ]
}
```


## is_se_logB
This function is for checking if the standard error reported in GWAS summary stats is a standard error of logistic beta. If the calculated and reported are almost identical that it is a selogB.  

```{r is_se_logB}
is_se_logB <- function(BETA,SE, PVALUE) {
  p_calculated <- 2*pnorm((abs(BETA) / SE),lower.tail = F)
  p_reported <- PVALUE
  data.frame(p_calculated, p_reported)
}
```


## calculate_prevalence

A function to calculate the sanple prevalence from a csv which has three columns: consortium, cases, controls. 

https://github.com/GenomicSEM/GenomicSEM/wiki/2.1-Calculating-Sum-of-Effective-Sample-Size-and-Preparing-GWAS-Summary-Statistics
```{r calculate_prevalence}
calculate_prevalence <- function(path_of_csv){
  #read the file and remove the NA columns and rows
  preva_csv <- read.csv(file = path_of_csv , header = T, sep = ';')
  preva_csv <-  preva_csv[, c('cases', 'controls')]
  preva_csv_noNA <- preva_csv[complete.cases(preva_csv), ]
  
  #calculated effective prevalence 
  #calculate sample prevalence for each cohort
  preva_csv_noNA$v <-preva_csv_noNA$cases/(preva_csv_noNA$cases+preva_csv_noNA$controls)
  #calculate cohort specific effective sample size
  preva_csv_noNA$EffN<-4*preva_csv_noNA$v*(1-preva_csv_noNA$v)*(preva_csv_noNA$cases+preva_csv_noNA$controls)
  #calculate sum of effective sample size: 
  eff_sample_size <- round(sum(preva_csv_noNA$EffN), 3)
  
  #print number of cases and controls, and effective sample size
  cat(paste0( 'Number of cases  ' , sum(preva_csv_noNA$cases), '\n', 
              'Number of contros  ', sum(preva_csv_noNA$controls), '\n', 
              'Effective sample size  ', round(sum(preva_csv_noNA$EffN), 3)
  ))
  
  #output the prevalenc when assigned to a variable 
  invisible(round(eff_sample_size, 3))
}
```

## locus.breaker

this function identifies loci in GWAS results, you nee to specify pvalue, chr and positon columns. 
```{r locus.breaker}
locus.breaker=function(res,p.sig=5e-8, p.limit=1e-5,hole.size=250000
                      ,p.label="p",chr.label="chr",pos.label="pos"){
  
  res=res[which(res[,p.label]<p.limit),]
  trait.res=c()
  for(j in 1:22){
    
    res.chr=res[which(res[,chr.label]==j),]
    if(nrow(res.chr)>1){
      holes=res.chr[,pos.label][-1]-res.chr[,pos.label][-length(res.chr[,pos.label])] 
      gaps=which(holes>hole.size)
      if(length(gaps)>0){
        for(k in 1:(length(gaps)+1)){
          
          if(k==1){
            res.loc=res.chr[1:(gaps[k]),]  
          }else if(k==(length(gaps)+1)){
            res.loc=res.chr[(gaps[k-1]+1):nrow(res.chr),]  
          }else{
            res.loc=res.chr[(gaps[k-1]+1):(gaps[k]),]
          }
          if(min(res.loc[,p.label])<p.sig){
            
            start.pos=min(res.loc[,pos.label],na.rm=T)
            end.pos=max(res.loc[,pos.label],na.rm=T)
            chr=j
            best.snp=res.loc[which.min(res.loc[,p.label]),]
            line.res=c(chr,start.pos,end.pos,unlist(best.snp))
            trait.res=rbind(trait.res,line.res)
          }
          
          
        }
      }else{
        res.loc=res.chr
        if(min(res.loc[,p.label])<p.sig)  {
          
          start.pos=min(res.loc[,pos.label],na.rm=T)
          end.pos=max(res.loc[,pos.label],na.rm=T)
          chr=j
          best.snp=res.loc[which.min(res.loc[,p.label]),]
          line.res=c(chr,start.pos,end.pos,unlist(best.snp))
          trait.res=rbind(trait.res,line.res)
        }
        
      }
      
    }else if(nrow(res.chr)==1){
      
      res.loc=res.chr
      if(min(res.loc[,p.label])<p.sig){
        start.pos=min(res.loc[,pos.label],na.rm=T)
        end.pos=max(res.loc[,pos.label],na.rm=T)
        chr=j
        best.snp=res.loc[which.min(res.loc[,p.label]),]
        line.res=c(chr,start.pos,end.pos,unlist(best.snp))
        trait.res=rbind(trait.res,line.res)
      }
      
      
    }
  }
  
  print(trait.res)
  trait.res=as.data.frame(trait.res,stringsAsFactors=FALSE)
  trait.res=trait.res[,-(which(names(trait.res)==chr.label))]
  names(trait.res)[1:3]=c("chr","start","end")
  trait.res
}
```

## assemble_3f 

This function take a list of chunks and returns a list in which each of the elements is the complete and assemble summary stats for each of the three factors. 
The function check the existence of the chunks, returns a warning indicating which chunks are missing and loads then ones that are not missing. That separetes according to the factor and outputs info about the unique number of SNPs per factor and the number of SNPs not estimated. The returning object is a list of summary statistics.
The input= number of expceted chunks is the index of the chunks. 
The function is meant to work with three factors!

```{r assemble_3f function}

assemble_3f <- function(n_expected_chunks, first_part_of_path, terminal_part_of_path){
  
  
      n_expected_chunks <- c(n_expected_chunks)
        
      #check if files exist and return the one that do not exist
      chunks_found <- lapply(c(n_expected_chunks), function(x)file.exists(paste0(first_part_of_path, x, terminal_part_of_path )))
      missing_chunks <- c(n_expected_chunks)[unlist(chunks_found)==F]
      
        #issue a warning indicating which chunks are missing and that will not be included in the final sumstats
            if((length(missing_chunks))>0) { 
              
              warning(    paste0( 'SOME CHUNKS ARE MISSING!', '\n',
                          length(n_expected_chunks) - length(missing_chunks), ' chunks were found!', '\n',
                          length(missing_chunks), ' chunks were NOT found!', '\n',
                          'The missing chunks are the ', paste0(missing_chunks, collapse = ' - ') , '\n', 
                          '\n')
                      )
              
            } else {
              
              cat(paste0( length(chunks_found) , ' chunks were found!', '\n', 
                          'There are not missing chunks :) ','\n' ,
                          '\n' ))
            }
      
      
      #load the chunks that have been found
      chunks_to_load <-  c(n_expected_chunks)[unlist(chunks_found)==T]
      
      chunks <- lapply( chunks_to_load , function(x)readRDS(paste0(first_part_of_path, x, terminal_part_of_path )))
      
      #for each chunk, separate F1 from F2 from F3
      
        #allocate three lists
        all_F1 <- list() #allocate the list
        all_F2 <- list() #allocate the list
        all_F3 <- list() #allocate the list
        
      
      #create a list of lists, in which each element of the list is a chunk, three lists one per factor
      for(i in (1:length(chunks))){
        all_F1[[i]] <- chunks[[i]][[1]]
        all_F2[[i]] <- chunks[[i]][[2]]
        all_F3[[i]] <- chunks[[i]][[3]]
      }
      
      #create the dataframe for F1 and F2 and F3
      F1 <-do.call(rbind, all_F1) 
      F2 <- do.call(rbind, all_F2)
      F3 <- do.call(rbind, all_F3)
      
      #create a list of summary stats, each element of the list are the summary stats
      sum_stats <- list(sumstats_F1 = F1, sumstats_F2 = F2, sumstats_F3 = F3)
      
      #calculate some useful qc information
        SNPs_unique <- list()
        SNP_error <- list()
      
        qc_info <- for( i in (1:length(sum_stats))){
        
            #number of SNP in total without error
            SNPs_unique[[i]]  <- cat(paste0('The number of unique SNPs in F', i , ' is ', length(unique(sum_stats[[i]]$SNP)), '\n'))
            
            #operator found
            cat('The lhs operators found in F',i, ' are ',  unique(sum_stats[[i]]$lhs), '\n')
            
            #number of SNP not estimated
            SNP_error[[i]] <-  cat(paste0('The number of not estimated SNPs in F', i , ' is ', nrow(sum_stats[[i]][sum_stats[[i]]$error != 0,]), '\n' , 
                                          '\n'))
            
        }
      
      
      #create the list of objects to be returned
      return_object <- list(sumstats_F1 = F1, sumstats_F2 = F2, sumstats_F3 = F3, SNPs_unique = SNPs_unique, SNP_error = SNP_error)
      
      invisible(return_object)
}

```


## append chunk

This funciton will merge chunks that are coming out the assemble_3f chunks. Important to provde a list of chunks were the elements of the list are list of F1,F2,F3 of summary statistics. It issues a warning if something is messed up 

```{r append chunk}
#it takes the output of the aseemble_3f function,
#  
# REMBER TO remove all the accesory outputs from assemble_3f

append_chunk <- function(list_complete ){
      
      
    #allocate list
    list_F1 <- list()
    list_F2 <- list()
    list_F3 <- list()
    
    
      for( i in c(1:length(list_complete))){
        list_F1[[i]] <- list_complete[[i]][[1]]
        list_F2[[i]] <- list_complete[[i]][[2]]
        list_F3[[i]] <- list_complete[[i]][[3]]
      }
        
        
      #merge the respective dataframes
      F1 <-do.call(rbind, list_F1) 
      F2 <- do.call(rbind, list_F2)
      F3 <- do.call(rbind, list_F3)
      
      sum_stats <- list(sumstats_F1 = F1, sumstats_F2 = F2, sumstats_F3 = F3)
      
      
      #calculate some useful qc information
      SNPs_unique <- list()
      SNP_error <- list()
      
      qc_info <- for( i in (1:length(sum_stats))){
            
            #number of SNP in total without error
            SNPs_unique[[i]]  <- cat(paste0('The number of unique SNPs in F',i, ' is ', length(unique(sum_stats[[i]]$SNP)), '\n'))
            
            #operator found
            cat('The lhs operators found in F',i, ' are ',  unique(sum_stats[[i]]$lhs), '\n')
            
            #number of SNP not estimated
            SNP_error[[i]] <-  cat(paste0('The number of not estimated SNPs in F',i, ' is ', nrow(sum_stats[[i]][sum_stats[[i]]$error != 0,]), '\n' , 
                                          '\n'))
        
      }
      
             #issue a warning if the cumulative numnber of unique SNPs in the merged dataset is different from the sum of the individual               unique SNPs per chunk
              row_F1 <- vector()
              row_F2 <- vector()
              row_F3 <- vector()
            for( i in c(1:length(list_complete))){
                row_F1[i] <- nrow(list_complete[[i]][[1]])
                row_F2[i] <- nrow(list_complete[[i]][[2]])
                row_F3[i] <- nrow(list_complete[[i]][[3]])
              }  
              
              #issue a warning if this arguments are different
              if(!identical(sum(row_F1),nrow(F1),sum(row_F2),nrow(F2),sum(row_F3),nrow(F3))){
                
                warning('The number of unique SNP is different between the merged and the sum of the individual chunks!!!')
                
              }
      
      #create a list of summary stats, each element of the list are the summary stats
      sum_stats <- list(sumstats_F1 = F1, sumstats_F2 = F2, sumstats_F3 = F3)
      
      return(sum_stats)
      
}

```

